# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wKHAceG9DLS9bUwCJ7mBsMD4fyqJsH87
"""

import sqlite3
import pandas as pd
!pip install geopandas
import geopandas as gpd
import numpy as np
!pip install folium
import folium
!pip install pyspark
import pyspark
import matplotlib.pyplot as plt
from folium.plugins import HeatMap
from pyspark.sql.window import Window
import pyspark.sql.functions as f

from google.colab import drive
drive.mount('/content/drive')

connection = sqlite3.connect('drive/MyDrive/FPA_FOD_20170508.sqlite')
data = pd.read_sql_query('SELECT * FROM Fires', connection)
pd.set_option('max_columns', None)

data2 = data[['FIRE_SIZE', 'DISCOVERY_DOY', 'STAT_CAUSE_DESCR']]

data = data[['FIRE_NAME', 'FIRE_YEAR', 
         'SOURCE_REPORTING_UNIT_NAME', 'STAT_CAUSE_DESCR',
         'FIRE_SIZE', 'LATITUDE',
         'LONGITUDE', 'STATE']]



x = len(data)
data.head()

spark = pyspark.sql.SparkSession.builder\
        .master('local[*]')\
        .appName('yr2145_hw2 notebook')\
        .getOrCreate()

sparkdf =spark.createDataFrame(data) 
sparkdf.head(5)

gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'
temperature = gpd.read_file('drive/MyDrive/normal_mly.kml', driver='KML')
temperature = pd.DataFrame(temperature.iloc[:,:-1].values, columns = list(temperature.columns.values)[:-1] )

temp = sparkdf.groupby(sparkdf.FIRE_YEAR).sum()

temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum")
temp = temp.sort("FIRE_YEAR")

x_axis = [val[0] for val in temp.select('FIRE_YEAR').collect()]
y_axis = [val[0] for val in temp.select('sum').collect()]

print(x_axis)
plt.plot(x_axis,y_axis)
plt.title('AREA BURNED IN ACRES EVERY YEAR')
plt.xlabel('YEAR OF OCCURANCE')
plt.ylabel('BURNED AREA IN 10 MILLION ACRES')
plt.show()

"""# AREA BURNED IN ACRES EVERY YEAR
IT WAS NOTICED THAT THE FOREST HAVE A TEMPORARY PEAK IN INCREASE IN WILDFIRES BEFORE THEY CAN REGENERATE WHICH CAUSES A TEMPORARY LIMBO OR REDUCTION IN THE AMOUNT OF WILDFIRES FOR SOME YEARS BEFORE THE FOREST CAN REGENERATE COMPLETELY AND THEN THE CYCLE REPEATS ITSELF ACCORDINGLY
"""

sparkdf.show()

sparkdf.select("STAT_CAUSE_DESCR").distinct().show()


temp = sparkdf.groupby(sparkdf.STAT_CAUSE_DESCR).sum()
temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum").sort("sum")
temp.show()

fig = plt.figure()
ax = fig.add_axes([0,0,3,3])
x_axis = [i[0] for i in sparkdf.select("STAT_CAUSE_DESCR").distinct().collect()]
y_axis = [i[0] for i in temp.select("sum").collect()]
ax.bar(x_axis,y_axis)
plt.title('AREA BURNED IN ACRES PER CATEGORY')
plt.xlabel('CAUSE OF FOREST FIRE')
plt.ylabel('BURNED AREA IN 10 MILLION ACRES')
plt.show()

"""# CAUSES OF FIRE

### WILDFIRES CAN BE DIVIDED INTO 2 SEPERATE CATEGORIES:
1. HUMAN CAUSED WILDFIRES (PREVENTABLE) e.g. FIREWORKS, RAILROADS, POWERLINE, SMOKING
2. NON HUMAN CAUSED WILDFIRES (NON PREVENTABLE) e.g. LIGHTNING

WHILE THE CAUSE OF THE **NATURAL** WILDFIRES MAY NOT BE MANY BUT THEIR IMPACT MAKES UP ABOUT **50%** OF TOTAL WILDFIRES AT ALMOST **8 MILLION ACRES** OF LAND BURNT BETWEEN 1992 AND 2015 THESE ARE FIRES THAT CANNOT BE PREVENTED.

THE MAJOR CONCERN IS ABOUT FIRES THAT CAN BE PREVENTED AND THEY INCLUDE THE WILDFIRES CAUSED DUE TO **HUMAN** INTERVENTION, A MAJOR FACTOR BEING **ARSON** WHICH IS **100%** PREVENTABLE IF AWARENESS IS SPREAD.
"""

from pyspark.sql.functions import lit
sparkdf = sparkdf.withColumn('count', lit(1))
here = sparkdf.select("FIRE_YEAR", "count")
here = here.withColumn('count', f.count('count').over(Window.partitionBy( sparkdf.FIRE_YEAR))).distinct().sort("FIRE_YEAR")

x_axis = [val[0] for val in here.select('FIRE_YEAR').collect()]
y_axis = [val[0] for val in here.select('count').collect()]

plt.plot(x_axis,y_axis)
plt.title('NUMBER OF FIRES')
plt.xlabel('YEAR OF OCCURANCE')
plt.ylabel('FIRES PER YEAR')
plt.show()

"""# NUMBERS OF FIRES SPREAD
THE NUMBER OF FIRES ALSO HAS THE VERY SAME IMPACT AS THE AREA BURNED WHICH CONFIRMS TO OUR LOGIC OF FOREST REGENERATION
"""

here = sparkdf.select("FIRE_SIZE", "count")
  
here.withColumn('count', f.count('count').over(Window.partitionBy( sparkdf.FIRE_SIZE))).distinct().sort("FIRE_SIZE").show(25)

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])
here = sparkdf.select("STATE", "count")
here = here.withColumn('count', f.count('count').over(Window.partitionBy( sparkdf.STATE))).distinct().sort("count")
x_axis = [val[0] for val in here.select('STATE').collect()]
y_axis = [val[0] for val in here.select('count').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('NUMBER OF FIRES PER STATE')
plt.xlabel('STATE OF OCCURANCE')
plt.ylabel('FIRES PER STATE')
plt.show()

"""# NUMBER OF FIRES PER STATE
THE TREND OF FIRES SPREAD PER STATE BY COUNT IS SIMPLE AND MAKES SENSE WHERE MOST OF WARM AND DRY STATES LIKE **CALIFORNIA, GEORGIA, TEXAS, NORTH CAROLINA AND FLORIDA** ARE TOP CONTRIBUTORS TO THE NUMBER OF FIRES THAT OCCURED IRRESPECTIVE OF SIZE.

ANOTHER SURPRISING FACTOR IS THAT MOST OF THE **TOP 10 STATES** COME FROM THE **WEST COAST** OF USA.

A SURPRISING FACTOR IS THAT **CALIFORNIA** HAS THE SAME AMOUNT OF FIRES AS THAT OF THE **BOTTOM 20** IN THE LIST COMBINED
"""

temp = sparkdf.groupby(sparkdf.STATE).sum()
temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum").sort("sum")

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])
x_axis = [val[0] for val in temp.select('STATE').collect()]
y_axis = [val[0] for val in temp.select('sum').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TOTAL SUM OF FIRE SIZE PER STATE')
plt.xlabel('STATE OF OCCURANCE')
plt.ylabel('FIRE SIZE')
plt.show()

"""# TOTAL SUM OF FIRE SIZE BURNED AND TRENDS

IT IS NOTICED THAT **ALASKA, IDAHO, CALIFORNIA, TEXAS, NEVADA** ARE THE TOP 5 CONTRIBUTORS OF WILDFIRES IN USA

SAME TREND WAS OBSERVED WHERE THE **WEST COAST** CONTRIBUTED TO ALMOST ALL THE **TOP 10 CONTIBUTORS**

THERE WAS A MAJOR SURPRISE THAT WAS NOTICED AS A MATTER OF FACT **ALASKA** WITH ITS DRY BUT COLD TEMPERATURE WAS THE **LARGEST CONTRIBUTOR OF WILDFIRES AND WAS ABLE TO CONTRIBUTE MORE AREA IN HECTARES THAN THAT OF THE NEXT TWO STATES (IDAHO, CALIFORNIA) COMBINED.** 

"From 1950 until 2009, he said, forest fires in Alaska have released CO2 equal to half of all carbon emissions from the European Union."
-https://www.dw.com/en/forest-fires-in-alaska-a-ticking-climate-time-bomb/a-18684423
"""

sparkdf =spark.createDataFrame(data2) 
sparkdf.head(5)

from pyspark.sql.functions import lit

sparkdf

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])

temp = sparkdf.withColumn('count', lit(1))
temp = temp.groupby(sparkdf.DISCOVERY_DOY).sum()

temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum").sort("DISCOVERY_DOY")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('sum').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE SIZE')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE SIZE')
plt.show()

"""# TRENDS IN WILDFIRE SPREAD BY AREA BURNED IN HECTARES


THERE IS A STRICT CORELATION AMONG ALL THE YEARS WHERE THE FIRE SEASON STARTS FROM **DAY 150 AND LASTS UNTIL DAY 250 **WITH WILDFIRES RAGING AT EXTREME EXTENTS.
THESE DATE TO THE **START OF JUNE TO MID SEPTEMBER**

ANOTHER OBSERVATION WAS MADE THAT THERE WAS A OUT OF CONTEXT INCRESE IN WILDFIRES IN OCTOBER END(HALOWEEN) AND JANUARY START(NEW YEAR) AND ON MARCH MID(TEXAS INDEPENDANCE DAY) AND APRIL START (SUMMERFEST)
CORELATION BETWEEN THESE EVENTS AND WILDFIRES IS STUDIED IN DETAIL IN FOLLOWING SECTIONS.

"""

#temp.show()
fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])

temp = temp.withColumnRenamed("sum(count)", "count")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('count').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE COUNTS')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE OCCURED')
plt.show()

"""# TRENDS IN FIRE COUNTS
FOLLOWS THE SAME DISTRIBUTION AND CONFIRMS TO THE THEORY OF FIREOWRK CORELATION MUCH MORE ROBUSTLY
"""

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])
temp = sparkdf.select(sparkdf.DISCOVERY_DOY,sparkdf.FIRE_SIZE,sparkdf.STAT_CAUSE_DESCR).filter(sparkdf.STAT_CAUSE_DESCR== "Fireworks").withColumn('count', lit(1))
temp = temp.groupby(sparkdf.DISCOVERY_DOY).sum()

temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum").sort("DISCOVERY_DOY")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('sum').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE SIZE FOR FIREWORKS')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE SIZE')
plt.show()

"""# STUDY ON FIREWORK RELATED EVENTS BY COUNT

IT IS CLEARLY VISIBLE THAT INFERENCE FROM THE FILDFIRE SPREAD BY AREA BURNED IN HEXTARES IS COMPLETELY TRUE ABOUT THE FIREWORK CORELATION.
IT WAS ALSO NOTICED THAT AT THE START OF JULY THERE WERE A LOT OF WILDFIRES CAUSED DUE TO FIREWORKS, THERE IS A CLEAR CORELATION WITH **4TH OF JULY** AND FIREWORK INCIDENTS AS THERE IS A HUGE PEAK AT THAT POINT.
"""

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])

temp = temp.withColumnRenamed("sum(count)", "count")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('count').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE COUNTS')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE OCCURED')
plt.show()

"""# AREA BURNED IN HECTARES IN FIREWORKK RELATED EVENTS

THERE WAS A CLEAR CORELATION BETWEEN FIRE SPREAD AND TIMESPAN OF LATE JUNE AND MID JULY, THIS IS THE PERIOD WHERE FIRECRACKER SALE IS PERMITTED IN SEVERAL STATES.
"""

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])
temp = sparkdf.select(sparkdf.DISCOVERY_DOY,sparkdf.FIRE_SIZE,sparkdf.STAT_CAUSE_DESCR).filter(sparkdf.STAT_CAUSE_DESCR== "Lightning").withColumn('count', lit(1))
temp = temp.groupby(sparkdf.DISCOVERY_DOY).sum()

temp = temp.withColumnRenamed("sum(FIRE_SIZE)", "sum").sort("DISCOVERY_DOY")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('sum').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE SIZE FOR LIGHTNING')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE SIZE')
plt.show()

"""# TRENDS IN TOTAL FIRE SIZE FOR LIGHTNING
THERE IS A CLEAR CORELATION AS TO WHY THERE IS AN INCRESE IN THE SEASONS DISCUSSED ABOVE.
LIGHTNING IN THE MAJOR CAUSE OF WILDFIRES AND THE WARM AND DRY CLIMATE SERVES AS THE CORRECT STARTER FOR OCEANIC WINDS TO FILL UP ITS PLACE BRINGING RAIN AND LIGHTNING, HOWEVER IN ARID CLIMATES OF WEST COAST THERE IS LITTLE TO NO RAIN, THIS IS A HUGELY UNAVOIDABLE PROBLEM FOR THE WILDFIRE DEPARTMENT.
"""

fig2 = plt.figure()
ax = fig2.add_axes([0,0,3,3])

temp = temp.withColumnRenamed("sum(count)", "count")

x_axis = [val[0] for val in temp.select('DISCOVERY_DOY').collect()]
y_axis = [val[0] for val in temp.select('count').collect()]

ax.bar(x_axis,y_axis)
plt.plot(x_axis,y_axis)
plt.title('TRENDS IN TOTAL FIRE COUNTS')
plt.xlabel('DATE OF DISCOVERY OF YEAR')
plt.ylabel('TOTAL FIRE OCCURED')
plt.show()

print(min(data['FIRE_SIZE']))
print(max(data['FIRE_SIZE']))

"""
# FIONA BASED MAPS TO VISUALIZE WILDFIRE TRENDS"""

data = data.loc[data['FIRE_SIZE'] > 100]

m = folium.Map(location = [40.44, -104.81],
               tiles = 'Stamen Terrain',
               zoom_start = 6)



Class_A = folium.FeatureGroup(name = '1,000 Acres to 10,000 Acres - Class D')
Class_B = folium.FeatureGroup(name = '10,000 Acres to 50,000 Acres - Class E')
Class_C = folium.FeatureGroup(name = 'More than 50,000 Acres - Class G')



for i, v in data.iterrows():
    
    size = float(v['FIRE_SIZE'])
    
    popup = """
    Name : %s<br>
    Size : %s<br>
    State : %s<br>
    Cause : %s<br>
    Year: %s<br>
    """ % (v['FIRE_NAME'], v['FIRE_SIZE'], 
           v['STATE'], v['STAT_CAUSE_DESCR'], 
           v['FIRE_YEAR'])
    
    
        
    if size in range(1000, 10000):
        folium.CircleMarker(location = [v['LATITUDE'], 
                                        v['LONGITUDE']],
                           radius = np.log(size),
                           weight = 0,
                           tooltip = popup,
                           color = '#feb24c',
                           fill_color = '#feb24c',
                           fill_opacity = 0.5,
                           fill = True).add_to(Class_A)
    
    if size in range(10000, 50000):
        folium.CircleMarker(location = [v['LATITUDE'], 
                                        v['LONGITUDE']],
                           radius = np.log(size)*1.4,
                           weight = 0,
                           tooltip = popup,
                           color = '#fc4e2a',
                           fill_color = '#fc4e2a',
                           fill_opacity = 0.6,
                           fill = True).add_to(Class_B)

    if size > 50000:
        folium.CircleMarker(location = [v['LATITUDE'], 
                                        v['LONGITUDE']],
                           radius = np.log(size)*1.8,
                           weight = 0,
                           tooltip = popup,
                           color = '##b10026',
                           fill_color = '#b10026',
                           fill_opacity = 0.7,
                           fill = True).add_to(Class_C)

Class_A.add_to(m)
Class_B.add_to(m)
Class_C.add_to(m)
folium.LayerControl(collapsed = False).add_to(m)

m

m = folium.Map(location = [40.44, -104.81],
               tiles = 'Stamen Terrain',
               zoom_start = 6)



Class_A = folium.FeatureGroup(name = '500 Acres to 1,000 Acres - Class D')

for i, v in data.iterrows():
    
    size = float(v['FIRE_SIZE'])
    
    popup = """
    Name : %s<br>
    Size : %s<br>
    State : %s<br>
    Cause : %s<br>
    Year: %s<br>
    """ % (v['FIRE_NAME'], v['FIRE_SIZE'], 
           v['STATE'], v['STAT_CAUSE_DESCR'], 
           v['FIRE_YEAR'])
    
    
        
    if size in range(500, 1000):
        folium.CircleMarker(location = [v['LATITUDE'], 
                                        v['LONGITUDE']],
                           radius = np.log(size),
                           weight = 0,
                           tooltip = popup,
                           color = '#feb24c',
                           fill_color = '#feb24c',
                           fill_opacity = 0.5,
                           fill = True).add_to(Class_A)

Class_A.add_to(m)
folium.LayerControl(collapsed = False).add_to(m)

m

m = folium.Map(location = [40.44, -104.81],
               tiles = 'Stamen Terrain',
               zoom_start = 6)



Class_A = folium.FeatureGroup(name = '500 Acres to 1,000 Acres - Class D')

for i, v in data.iterrows():
    
    size = float(v['FIRE_SIZE'])
    
    popup = """
    Name : %s<br>
    Size : %s<br>
    State : %s<br>
    Cause : %s<br>
    Year: %s<br>
    """ % (v['FIRE_NAME'], v['FIRE_SIZE'], 
           v['STATE'], v['STAT_CAUSE_DESCR'], 
           v['FIRE_YEAR'])
    
    
        
    if size in range(300, 500):
        folium.CircleMarker(location = [v['LATITUDE'], 
                                        v['LONGITUDE']],
                           radius = np.log(size),
                           weight = 0,
                           tooltip = popup,
                           color = '#feb24c',
                           fill_color = '#feb24c',
                           fill_opacity = 0.5,
                           fill = True).add_to(Class_A)

Class_A.add_to(m)
folium.LayerControl(collapsed = False).add_to(m)

m

map_hooray = folium.Map(location=[40.44, -104.81],tiles = 'Stamen Terrain',
                    zoom_start = 5) 

data['LATITUDE'] = data['LATITUDE'].astype(float)
data['LONGITUDE'] = data['LONGITUDE'].astype(float)
heat_data = data.loc[data['FIRE_SIZE'] > 1000]
heat_data = data[['LATITUDE', 'LONGITUDE']]
heat_data = heat_data.dropna(axis=0, subset=['LATITUDE','LONGITUDE'])

heat= [[row['LATITUDE'],row['LONGITUDE']] for index, row in heat_data.iterrows()]

HeatMap(heat).add_to(map_hooray)

map_hooray

data = data.loc[data['STAT_CAUSE_DESCR'] == "Fireworks"]

map_hooray = folium.Map(location=[40.44, -104.81],tiles = 'Stamen Terrain',
                    zoom_start = 5) 

data['LATITUDE'] = data['LATITUDE'].astype(float)
data['LONGITUDE'] = data['LONGITUDE'].astype(float)
heat_data = data.loc[data['FIRE_SIZE'] > 1000]
heat_data = data[['LATITUDE', 'LONGITUDE']]
heat_data = heat_data.dropna(axis=0, subset=['LATITUDE','LONGITUDE'])

heat= [[row['LATITUDE'],row['LONGITUDE']] for index, row in heat_data.iterrows()]

HeatMap(heat).add_to(map_hooray)

map_hooray